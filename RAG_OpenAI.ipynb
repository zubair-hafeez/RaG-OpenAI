{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubair-hafeez/RaG-OpenAI/blob/main/RAG_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbVn0kNJfAwx"
      },
      "source": [
        "## Retrieval augmented generation\n",
        "\n",
        "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
        "\n",
        "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoED3uKQfAw2"
      },
      "outputs": [],
      "source": [
        "! pip install langchain\n",
        "! pip install openai\n",
        "! pip install langchain-community\n",
        "! pip install pypdf\n",
        "! pip install tiktoken\n",
        "! pip install chromadb\n",
        "! pip install lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNU3O0xFfAw5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = userdata.get('OPENAI_API_KEY')\n",
        "userdata.get('DUMMY_API_KEY')"
      ],
      "metadata": {
        "id": "XPfnJQrqzxBu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBxmbMafAw7"
      },
      "source": [
        "## PDFs\n",
        "\n",
        "Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmIG75BbfAw9"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"Sample.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFrJxVjVfAw9"
      },
      "source": [
        "Each page is a `Document`.\n",
        "\n",
        "A `Document` contains text (`page_content`) and `metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RGod-Q4fAw9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "len(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlQzjTuEfAw-"
      },
      "outputs": [],
      "source": [
        "page = pages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHdDwA-sfAw-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(page.page_content[0:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwVV9xFOfAw_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "page.metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIqzGcysfAxA"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt-mx1UwfAxA"
      },
      "outputs": [],
      "source": [
        "chunk_size =26\n",
        "chunk_overlap = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o893hX-zfAxB"
      },
      "outputs": [],
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jChzx4vfAxB"
      },
      "source": [
        "Why doesn't this split the string below?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqPVkLOQfAxB"
      },
      "outputs": [],
      "source": [
        "text1 = 'abcdefghijklmnopqrstuvwxyz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE7gQMRrfAxC"
      },
      "outputs": [],
      "source": [
        "r_splitter.split_text(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klT16pWCfAxC"
      },
      "outputs": [],
      "source": [
        "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw9kRAvqfAxC"
      },
      "outputs": [],
      "source": [
        "r_splitter.split_text(text2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc9VrTAmfAxD"
      },
      "source": [
        "Ok, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-ELV4AsfAxD"
      },
      "outputs": [],
      "source": [
        "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dARDBMi9fAxD"
      },
      "outputs": [],
      "source": [
        "r_splitter.split_text(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_1-jmKOfAxD"
      },
      "outputs": [],
      "source": [
        "c_splitter.split_text(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3jS8LuufAxD"
      },
      "outputs": [],
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separator = ' '\n",
        ")\n",
        "c_splitter.split_text(text3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUjw-c7WfAxE"
      },
      "source": [
        "Try your own examples!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKbCMl00fAxE"
      },
      "source": [
        "## Recursive splitting details\n",
        "\n",
        "`RecursiveCharacterTextSplitter` is recommended for generic text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LomPUVTyfAxE"
      },
      "outputs": [],
      "source": [
        "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
        "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
        "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
        "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
        "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
        "Sentences have a period at the end, but also, have a space.\\\n",
        "and words are separated by space.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iJrj0-jfAxE"
      },
      "outputs": [],
      "source": [
        "len(some_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVJLwkkZfAxE"
      },
      "outputs": [],
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separator = ' '\n",
        ")\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6QdwthZfAxF"
      },
      "outputs": [],
      "source": [
        "c_splitter.split_text(some_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW_DKOj_fAxF"
      },
      "outputs": [],
      "source": [
        "r_splitter.split_text(some_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCnQHXbcfAxf"
      },
      "source": [
        "# Vectorstores and Embeddings\n",
        "\n",
        "Recall the overall workflow for retrieval augmented generation (RAG):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55vQ-MmwfAxg"
      },
      "source": [
        "We just discussed `Document Loading` and `Splitting`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqvIHWtJfAxg"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"Sample.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g0Of0csfAxh"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWkbuHBfAxh"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhCwfgj5fAxh",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kafd_POTfAxh"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Let's take our splits and embed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP5ja60zfAxh",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHtENPACfAxi"
      },
      "outputs": [],
      "source": [
        "word1 = \"i love burgers\"\n",
        "word2 = \"the weather is great today\"\n",
        "word3 = \"Its raining outside\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6_rd4YafAxi"
      },
      "outputs": [],
      "source": [
        "embedding1 = embedding.embed_query(word1)\n",
        "embedding2 = embedding.embed_query(word2)\n",
        "embedding3 = embedding.embed_query(word3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkHGTPqffAxi"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fyGWT_ifAxi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "np.dot(embedding2, embedding3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib6RqnfdfAxk"
      },
      "source": [
        "## Vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLs7b7xkfAxk"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6XvRGMfAxk"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q4FhDOBfAxk"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUUQBrdqfAxl"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79VncbEAfAxl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZZd5QVafAxl"
      },
      "source": [
        "### Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_On33I2BfAxl"
      },
      "outputs": [],
      "source": [
        "question = \"What is Pak Angels Generative AI Training Program?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUkXS_7fAxl"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk--QXm7fAxl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-YSn88ZfAxm"
      },
      "source": [
        "Let's save this so we can use it later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwcG2Y85fAxn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR4ofzjVfAxn"
      },
      "source": [
        "# Retrieval\n",
        "\n",
        "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow.\n",
        "\n",
        "Let's get our vectorDB from before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOB4M4FnfAxn"
      },
      "source": [
        "## Vectorstore retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFkIXin6fAxp"
      },
      "source": [
        "### Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAhGspr7fAxq"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gI6jI3mfAxq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J5CypOAfAxs",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3onVs9FNfAx1"
      },
      "source": [
        "# Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzqF_w52fAx2"
      },
      "source": [
        "We discussed `Document Loading` and `Splitting` as well as `Storage` and `Retrieval`.\n",
        "\n",
        "Let's load our vectorDB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKGiCRokfAx2"
      },
      "source": [
        "The code below was added to assign the openai LLM version filmed until it is deprecated, currently in Sept 2023.\n",
        "LLM responses can often vary, but the responses may be significantly different when using a different model version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrAzikSgfAx2"
      },
      "outputs": [],
      "source": [
        "llm_name = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZNcwuSsfAx2"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "persist_directory = 'docs/chroma/'\n",
        "embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raCKvB8KfAx3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsjYXSfgfAx3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "question = \"What are major topics for this class?\"\n",
        "docs = vectordb.similarity_search(question,k=3)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVXejxmpfAx3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i208LDXwfAx3"
      },
      "source": [
        "### RetrievalQA chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiMiESZ0fAx4"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwrwTu_6fAx5"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLf-BowKfAx5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "result = qa_chain({\"query\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahWV8rGUfAx5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PdRoClDfAx6"
      },
      "source": [
        "### Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYJdiVXGfAx6"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EIEd-6hfAx7"
      },
      "outputs": [],
      "source": [
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What are the objectives of Pak Angels generative ai essential training?\").content"
      ],
      "metadata": {
        "id": "MorF4nq7qxGw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGfSPbPMfAx7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "question = \"What is the agenda for module 1\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCpQOQe1fAx8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "result[\"source_documents\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt6e1UemfAyG"
      },
      "source": [
        "Note, The LLM response varies. Some responses **do** include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qIaB8vAtIRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "https://learn.deeplearning.ai/courses/langchain-chat-with-your-data/\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7t6sBdGotJSI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bs4AhqDXtKde"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}